# Q&A

导致复制超时的场景以及故障处理

超过Client-output-buffer-limit 这可能发生在以下几种情况：

a)	建立主从全同步的过程中，有两个原因造成：同步时间过长、单位时间写入量过大。Master主动断开连接。
master日志报错：
Client id=10461 addr=192.168.166.57:60450 fd=508 name= age=24 idle=24 flags=S db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=1         
5538 oll=49496 omem=1228932544 events=r cmd=shardsync scheduled to be closed ASAP for overcoming of output buffer limits.
b)	主从同步已经完全建立，单位时间写入量突增。Master主动断开连接。
master日志报错：
Client id=220 addr=127.0.0.1:23972 age=1213 idle=0 flags=S db=0 qbuf=0 qbuf-free=0 obl=0 oll=9350 omem=268436720 events=rw cmd=replconf 
scheduled to be closed ASAP for overcoming of output buffer limits
c)	半同步过程中，单位时间写入量突增。Master主动断开连接。
Master日志报错：
Client id=809 addr=127.0.0.1:44100  age=2 idle=2 flags=S  qbuf=0 qbuf-free=0 obl=14717 oll=13082 omem=268442640 events=r cmd=psync scheduled to be closed ASAP for overcoming of output buffer limits.
以上可以通过info replication 中的lag来告警。lag>10认为主从有问题，需要做告警。
收到以上告警：
1、	去master上查询到相关日志。
2、	确定问题，在slave上做slaveof no one操作。
3、	查询问题原因。
如果是QPS增大导致，动态增大maxmemory, Client-output-buffer-limit slave配置的值。
如果是业务写入大key，可以使用工具redis-traffic-stats来做快速确认，联系业务做处理。恢复同步，暂时调大Client-output-buffer-limit slave，slave 提前做好flushDB操作。恢复主从关系。

超时断线

a)	Master执行慢查询，超过repl-timeout。Slave主动断线。
Slave日志报错：
MASTER timeout: no data nor PING received...
Connection with master lost.
Caching the disconnected master state.
Connecting to MASTER 127.0.0.1:6545
I/O error reading SLOT DESC LEN from master: Connection timed out
Master端可通过slowlog进行排查。确认后，通知业务方修改。
b)	Master做主从同步耗时长，超时repl-timeout。Slave主动断线。除非repl-timeout设置的特别小，不然一般在线上是不可能发生超时情况。
Master日志报错：
Connection with slave 127.0.0.1:6398 lost.
Slave asks for synchronization
Full resync requested by slave.
Waiting for next BGSAVE for SYNC
Slave日志报错：
Connecting to MASTER 127.0.0.1:6397
MASTER <-> SLAVE sync started
Non blocking connect for SYNC fired the event.
Master replied to PING, replication can continue...
Partial resynchronization not possible (no cached master)
Full resync from master: df6f70ca1a179158411ab906a36e924a6762a7ed:1
Timeout receiving bulk data from MASTER... If the problem persists try to set the 'repl-timeout' parameter in redis.conf to a larger value
发生这种错误时，slave日志会给予提示，可以动态将repl-timeout调试大一些。
Ps:全量同步过程耗时简化为串行的4步：
Master执行bgsave, fork子进程保存和压缩RDB文件；耗时T1.

Master把RDB文件发送给Slave过程；耗时T2.

Slave flush自己的数据；耗时T3.

Slave Load RDB ; 耗时T4.
2.8对这块做了改进，在T1，T2，T3，T4这几个阶段，master和slave一直在相互ping（最长10s），避免对方断线。具体见附件。
在线上基本上不会因为这个原因导致断线。
* [FIX] Replication timeout handling greatly improved, now the slave is able
to ping the master while removing the old data from memory, and while
loading the new RDB file. This avoid false timeouts sensed by maater.
c)	Slave执行慢查询，超过repl_timeout。Master断线。
Master错误日志：
Disconnecting timedout slave: 127.0.0.1:6546
Connection with slave 127.0.0.1:6546 lost.
Slave错误日志：
Connection with master lost.
Caching the disconnected master state.
Connecting to MASTER 127.0.0.1:6545
MASTER <-> SLAVE sync started 开始同步
Trying a partial resynchronization (request 79cb4c6b6a2f3082f2df46baba23b56d54317670:1).
slave端可通过slowlog进行排查。确认后，通知业务方修改。


超过repl_backlog
Slave日志：
Trying a partial resynchronization (request 6bb7d94ee19315985894f72aa9a3699e5f60b4cf:1).
Full resync from master: 79cb4c6b6a2f3082f2df46baba23b56d54317670:0, shardid: 79cb4c6b6a2f3082f2df46baba23b56d54317670


可以通过info replication 中的lag来告警。lag>10认为主从有问题，需要做告警。


集群迁移不支持的命令
由于集群环境参与运算的key可能分布在不同节点，一下命令可能报(error) CROSSSLOT Keys in request don't hash to the same slot
   * SDIFFSTORE 
   * SINTERSTORE 
   * SUNIONSTORE 
   * ZUNIONSTORE
   * ZINTERSTORE
   * RPopLPush  支持相同key执行改命令
   * BRPopLPush 支持相同key执行改命令