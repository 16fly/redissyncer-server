# redissyncer成长记

### 诞生
redissyncer是京东云自研的一套redis同步工具。起初是2018年某家在线广告公司需要将redis从自有机房迁移到云上。由于客户系统承载着大量结算缓存和业务缓存所以要求在迁移过程中不能有业务中断。当时有一些开源工具，但是不满足要求。主要是由于版本问题，客户用的redis版本是4.0而当时开源的工具只支持3.28及以下版本。所以我们临时写了一个临时程序帮助客户完成了迁移

### 1.0
大概2019年7月份，我们想能不能在做一套能够cover住redis数据流转大部分场景的通用工具，于是有了redissyncer 1.0版本。在1.0版本我们主要实现了以下功能
* 数据源及目标校验
* 多任务模式
* 自动适配源及目标版本
* 跨版本同步:低版本=>高版本
* 原生集群同步
* 大KV的拆解
* 任务状态持久化
* 梳理了任务的增删改查接口
  
1.0完成以后我们很快迎来了第一个用户，互联网行业，redis单实例，数据体量不大20Gb左右。起初我们觉得我们的产品足以应付这样的场景，但是在第一次试迁的时候出现了OOM。经过一系列排查,根因主要有两个：一个是由于我们启动程序的时候堆内存使用默认值造成堆内存过小，这个可以通过启动参数修复；另一个是由于用户使用redis存储session，某一list的value足有几个GB。虽然我们对于大key有拆分方案，但是切分的每批次的value还是太大。于是我们调整了每批次value的数量从1000降到200后，顺利完成了迁移任务。
第二个用户是游戏行业的用户，用户需要将自有idc中的redis迁移到京东云的rds。在使用我们的产品之前，用户自己找过若干开源产品但都不符合要求。由于用户的实例数量较多，所以用户决定使用我们的工具自行迁移。经过一个下午的培训远程培训，用户很快上手第一个实例迁移很顺利。在接下来的几天用户通过我们的工具陆续完成迁移工作，并反馈中给予产品很高评价

### 2.0
大约2019年11月底，我们完成了2.0版本的开发，在新版本中我们补充了如下功能
* 同步模式拆分：全量、增量和全量+增量
* 断点续传：通过targetoffset续传，如果offset值已过期，该任务作废
* 离线rdb或aof文件加载

考虑到有些用户的redis作为缓存使用，但是可能由于业务需要需要实时同步最近的缓存以避免缓存击穿。我们对于同步模式进行了拆分，支持单独的增量同步。离线文件我们支持流式加载，用户可以只提供rdb或aof文件的url即可。
大约2019年12月我们迎来了第一个金融级用户。用户需要将原生redis集群迁移到自研的redis集群。目标集群节点数多大16*2即16对主从构成的集群，目前已通过测试环境下的POC。
2.0版本完成后redissyncer大概是这个样子：
![avatar](../img/transfor.jpg)

### 未来
作为一款数据传输工具我们一直在思考它的最终形态是什么样子，应该具备怎样的功能，能够支持什么样的场景。
首先从场景角度来讲最大最复杂的场景当属双活场景，要求两中心业务同时可写，数据实时同步。同时要求在网络瞬端的情况下可以进行消息堆积已经redissyncer本身发生故障时的自动恢复。支持以上场景知道需要双向同步和对接消息队列两个大feature，这也是我们下一步的研发目标。
另一个是跨云托管redis如何实现增量迁移，不能直接访问托管数据库节点是个巨大的障碍，也是我们下一步要重点攻克的课题。